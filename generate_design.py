"""
æ€»ä½“è®¾è®¡ + æ¨¡å—è¯¦ç»†è®¾è®¡ Agent

æµç¨‹ï¼š
1. ç”Ÿæˆ5ä»½æ€»ä½“è®¾è®¡æ–‡æ¡£ design_overall_[1-5].mdï¼ˆè½®æ¢ doc_writer æ¨¡å‹ï¼‰
2. å¤šæ¨¡å‹è½®è¯¢å¯¹5ä»½æ–‡æ¡£æ‰“åˆ†
3. é€‰å‡ºæœ€é«˜åˆ†ï¼Œåˆå¹¶å»ºè®®ï¼Œä¼˜åŒ–ç”Ÿæˆ design_overall.md
4. ä» requirement_leader.md è·å–æ¨¡å—åˆ—è¡¨
5. æŒ‰æ¨¡å—ä¾æ¬¡ç”Ÿæˆè¯¦ç»†è®¾è®¡æ–‡æ¡£ design_module_${module}.md
6. å¯¹æ¯ä¸ªæ¨¡å—æ–‡æ¡£è¿›è¡Œå¤šæ¨¡å‹å®¡æ ¸â†’ä¼˜åŒ–å¾ªç¯ï¼ˆä¸Šé™ REVIEW_OPTIMIZE_FACTOR å—æ¨¡å‹æ•°æ¬¡ï¼‰
7.1 æ¥å£å¯¹é½ï¼ˆALIGN_ROUNDS è½®ï¼‰
7.2-7.4 å…¨å±€å®¡æ ¸â†’ä¼˜åŒ–å¾ªç¯ï¼ˆä¸Šé™ REVIEW_OPTIMIZE_FACTOR å—æ¨¡å‹æ•°æ¬¡ï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
    python generate_design.py
"""

import os
import re
import sys
import json
import time
import logging
import yaml
from datetime import datetime
from ask_llm import OpenCodeClient

# ============================================================
# å¯é…ç½®å¸¸é‡
# ============================================================

LEADER_FILE    = "requirement_leader.md"
OVERALL_FILE   = "design_overall.md"

# æ­¥éª¤1ï¼šç”Ÿæˆå€™é€‰æ€»ä½“è®¾è®¡æ–‡æ¡£çš„ä»½æ•°
GENERATE_CANDIDATES = 5

# æ­¥éª¤7.1ï¼šæ¥å£å¯¹é½å¾ªç¯è½®æ•°
ALIGN_ROUNDS = 5

# æ­¥éª¤6 / 7.2-7.4ï¼šå®¡æ ¸-ä¼˜åŒ–å¾ªç¯è°ƒç”¨ä¸Šé™ = REVIEW_OPTIMIZE_FACTOR å— reviewer æ¨¡å‹æ•°
# å…¬å¼ï¼š(len(doc_reviewer_models) + 1) * REVIEW_OPTIMIZE_FACTOR
REVIEW_OPTIMIZE_FACTOR = 5

# ============================================================
# æ—¥å¿—é…ç½®
# ============================================================

LOG_FORMAT = "%(asctime)s [%(levelname)s] %(message)s"
logging.basicConfig(
    level=logging.INFO,
    format=LOG_FORMAT,
    handlers=[logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger(__name__)

# ============================================================
# å·¥å…·å‡½æ•° - LLM è°ƒç”¨åŒ…è£…ï¼ˆå¸¦æ—¥å¿—ï¼‰
# ============================================================

_llm_call_index = 0  # å…¨å±€è°ƒç”¨è®¡æ•°å™¨

def llm_call(client, prompt: str, model=None, step_desc: str = "") -> str:
    """
    ç»Ÿä¸€çš„ LLM è°ƒç”¨å…¥å£ï¼Œè‡ªåŠ¨è®°å½•ï¼š
    - æ­¥éª¤æè¿°ã€è°ƒç”¨åºå·
    - å®Œæ•´ prompt
    - å®Œæ•´ response
    - è€—æ—¶
    """
    global _llm_call_index
    _llm_call_index += 1
    idx = _llm_call_index
    model_display = model or "é»˜è®¤æ¨¡å‹"

    logger.info("=" * 60)
    logger.info(f"ğŸ“¤ ç¬¬ {idx} æ¬¡ LLM è°ƒç”¨ [æ¨¡å‹: {model_display}] â€” {step_desc}")
    logger.info(f"ğŸ“ Prompt:\n{prompt}")
    logger.info("-" * 60)

    t0 = time.time()
    response = client.chat(prompt, model=model)
    elapsed = time.time() - t0

    if response:
        logger.info(f"ğŸ“¥ Responseï¼ˆè€—æ—¶ {elapsed:.1f}sï¼‰:\n{response}")
    else:
        logger.warning(f"âš ï¸ LLM è¿”å›ä¸ºç©ºï¼ˆè€—æ—¶ {elapsed:.1f}sï¼‰")
    logger.info("=" * 60)
    return response or ""


# ============================================================
# å·¥å…·å‡½æ•° - é…ç½®åŠ è½½
# ============================================================

def load_config(config_path='agents_config.yaml'):
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"Error: é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
        return {}


from doc_utils import read_file, read_requirement_docs, read_module_design_docs


# ============================================================
# å·¥å…·å‡½æ•° - ç»“æ„åŒ–å“åº”è§£æ
# ============================================================

def parse_review_response(response: str) -> dict:
    """
    è§£æå®¡æ ¸å“åº”ï¼ŒæœŸæœ› LLM è¿”å›ç»“æ„åŒ– JSONï¼š
    {
        "satisfied": true/false,
        "issues": ["é—®é¢˜1", "é—®é¢˜2", ...],
        "suggestions": "æ±‡æ€»å»ºè®®æ–‡å­—",
        "score": 85
    }
    è¿”å›è§£æåçš„ dictï¼Œè§£æå¤±è´¥æ—¶ç»™å‡ºé»˜è®¤å€¼ã€‚
    """
    if not response:
        return {"satisfied": False, "issues": [], "suggestions": "", "score": 0}

    # å°è¯•æå– JSON å—
    try:
        # åŒ¹é…æœ€å¤–å±‚ {...}
        match = re.search(r'\{[\s\S]*\}', response)
        if match:
            raw = match.group()
            raw = raw.replace("'", '"')  # å…¼å®¹å•å¼•å·
            data = json.loads(raw)
            score_raw = data.get("score", 0)
            score = int(str(score_raw).strip()) if str(score_raw).strip().isdigit() else 0
            issues = data.get("issues", [])
            if isinstance(issues, str):
                issues = [issues] if issues.strip() else []
            return {
                "satisfied": bool(data.get("satisfied", False)),
                "issues": issues,
                "suggestions": data.get("suggestions", ""),
                "score": score,
            }
    except Exception:
        pass

    # æ­£åˆ™å…œåº•ï¼šå°è¯•æå– score å’Œ satisfied
    score_match = re.search(r'"score"\s*:\s*"?(\d+)"?', response)
    satisfied_match = re.search(r'"satisfied"\s*:\s*(true|false)', response, re.IGNORECASE)
    score = int(score_match.group(1)) if score_match else 0
    satisfied = satisfied_match and satisfied_match.group(1).lower() == "true"
    return {
        "satisfied": satisfied,
        "issues": [],
        "suggestions": response.strip()[:800],
        "score": score,
    }


def is_all_satisfied(review_parsed_list: list[dict]) -> bool:
    """åˆ¤æ–­æ‰€æœ‰å®¡æ ¸ç»“æœæ˜¯å¦å…¨éƒ¨æ»¡æ„ï¼ˆsatisfied=true ä¸” issues åˆ—è¡¨ä¸ºç©ºï¼‰ã€‚"""
    return all(
        r.get("satisfied", False) and len(r.get("issues", [])) == 0
        for r in review_parsed_list
    )


def merge_suggestions_from_parsed(parsed_list: list[dict], reviewer_labels: list[str]) -> str:
    """ä»ç»“æ„åŒ–å®¡æ ¸ç»“æœä¸­åˆå¹¶ issues å’Œ suggestionsï¼Œè¿‡æ»¤æ‰æ»¡æ„çš„è¿”å›ã€‚"""
    parts = []
    for label, parsed in zip(reviewer_labels, parsed_list):
        if parsed.get("satisfied") and not parsed.get("issues"):
            continue
        issues = parsed.get("issues", [])
        suggestions = parsed.get("suggestions", "")
        if issues:
            issues_str = "\n".join(f"  - {iss}" for iss in issues)
            parts.append(f"[{label}] å…·ä½“é—®é¢˜ï¼š\n{issues_str}")
        if suggestions:
            parts.append(f"[{label}] ç»¼åˆå»ºè®®ï¼š{suggestions}")
    return "\n\n".join(parts)


REVIEW_OUTPUT_FORMAT = """\
è¯·ä»…è¿”å›ä»¥ä¸‹ JSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼š
{
    "satisfied": true æˆ– false,
    "issues": ["å…·ä½“é—®é¢˜1ï¼ˆæŒ‡å‡ºä½ç½®+åŸå› ï¼‰", "å…·ä½“é—®é¢˜2", ...],
    "suggestions": "ç»¼åˆæ”¹è¿›å»ºè®®ï¼ˆå¦‚æ— é—®é¢˜å¯ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰",
    "score": 0åˆ°100çš„æ•´æ•°
}
è¯´æ˜ï¼š
- satisfied ä¸º true å½“ä¸”ä»…å½“æ–‡æ¡£å®Œå…¨æ»¡è¶³è¦æ±‚ï¼Œissues åˆ—è¡¨ä¸ºç©ºï¼›
- æœ‰ä»»ä½•é—®é¢˜æ—¶ satisfied å¿…é¡»ä¸º falseï¼Œå¹¶åœ¨ issues ä¸­é€æ¡åˆ—å‡ºï¼›
- score åæ˜ æ•´ä½“è´¨é‡ï¼Œæ»¡åˆ†100ã€‚"""


SCORE_OUTPUT_FORMAT = """\
è¯·ä»…è¿”å›ä»¥ä¸‹ JSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼š
{
    "issues": ["å…·ä½“é—®é¢˜1ï¼ˆæŒ‡å‡ºä½ç½®+åŸå› ï¼‰", "å…·ä½“é—®é¢˜2", ...],
    "suggestions": "ç»¼åˆæ”¹è¿›å»ºè®®",
    "score": 0åˆ°100çš„æ•´æ•°
}
è¯´æ˜ï¼š
- issues ä¸­é€æ¡åˆ—å‡ºæ‰€æœ‰ä¸åˆç†æˆ–å¯ä¼˜åŒ–çš„åœ°æ–¹ï¼›å¦‚æ— é—®é¢˜ issues ä¸ºç©ºåˆ—è¡¨ï¼›
- score åæ˜ æ•´ä½“è´¨é‡ï¼Œæ»¡åˆ†100ã€‚"""


# ============================================================
# æ­¥éª¤ 1: ç”Ÿæˆ5ä»½æ€»ä½“è®¾è®¡æ–‡æ¡£
# ============================================================

def step1_generate_overall(client, doc_writer_models):
    logger.info("\n" + "=" * 60)
    logger.info(f"ã€æ­¥éª¤1ã€‘ ç”Ÿæˆ {GENERATE_CANDIDATES} ä»½æ€»ä½“è®¾è®¡æ–‡æ¡£ï¼ˆè½®æ¢ doc_writer æ¨¡å‹ï¼‰")
    logger.info("=" * 60)

    req_content = read_requirement_docs()
    leader_content = read_file(LEADER_FILE)

    for i in range(1, GENERATE_CANDIDATES + 1):
        model = doc_writer_models[(i - 1) % len(doc_writer_models)]
        model_display = model or "é»˜è®¤æ¨¡å‹"
        doc_name = f"design_overall_{i}.md"
        logger.info(f"\n[{i}/{GENERATE_CANDIDATES}] ç”Ÿæˆ {doc_name}ï¼ˆæ¨¡å‹: {model_display}ï¼‰...")

        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è½¯ä»¶æ¶æ„å¸ˆã€‚
è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹éœ€æ±‚æ–‡æ¡£å’Œæ¨¡å—æ‹†åˆ†è®¾è®¡æ–‡æ¡£ï¼Œå……åˆ†ç†è§£ä¸šåŠ¡å…¨è²Œåï¼Œç”Ÿæˆæ€»ä½“è®¾è®¡æ–‡æ¡£ {doc_name}ã€‚

æ³¨æ„ï¼šä½ ç”Ÿæˆçš„æ–‡æ¡£åä¸º {doc_name}ï¼Œè¯·å°†å†…å®¹ä¿å­˜åˆ°è¯¥æ–‡ä»¶ã€‚

ã€è¾“å…¥æ–‡æ¡£ã€‘
{req_content}

{leader_content}

ã€è®¾è®¡è¦æ±‚ã€‘æ–‡æ¡£å¿…é¡»åŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼Œä¸”æ¯ä¸ªç« èŠ‚éœ€æœ‰å…·ä½“å†…å®¹è€Œéæ¨¡ç³Šå ä½ï¼š

1. æ€»ä½“ä¸šåŠ¡æ¶æ„
   - åˆ—å‡ºæ‰€æœ‰æ¨¡å—åŠå…¶èŒè´£å±‚æ¬¡
   - ç”¨ ASCII æˆ–æ–‡å­—æè¿°æ¨¡å—é—´ä¾èµ–å…³ç³»å›¾ï¼ˆæ˜ç¡®æ ‡æ³¨ä¾èµ–æ–¹å‘ï¼‰

2. ä¸šåŠ¡é©±åŠ¨æ¨¡å¼
   - é€ä¸€åˆ—å‡ºæ¯ä¸ªæ¨¡å—çš„é©±åŠ¨æ–¹å¼ï¼šUIäº¤äº’ã€æµç¨‹é©±åŠ¨ã€å®šæ—¶ä»»åŠ¡æˆ–äº‹ä»¶é©±åŠ¨
   - è¯´æ˜é€‰æ‹©è¯¥é©±åŠ¨æ–¹å¼çš„ç†ç”±

3. æ¨èè®¾è®¡æ¨¡å¼
   - åˆ†ææ•´ä¸ªä¸šåŠ¡æ¶æ„æ˜¯å¦é€‚åˆæŸç§è®¾è®¡æ¨¡å¼ï¼ˆå¦‚ CQRSã€Event Sourcingã€Sagaã€Repository ç­‰ï¼‰
   - å¦‚é€‚ç”¨ï¼Œè¯´æ˜åº”ç”¨æ–¹å¼å’Œæ”¶ç›Šï¼›å¦‚æ²¡æœ‰ï¼Œè¯´æ˜åŸå› 

4. ä¸šåŠ¡æµæ—¶åºå›¾
   - é’ˆå¯¹æœ€æ ¸å¿ƒçš„ 2-3 ä¸ªä¸»è¦ä¸šåŠ¡åœºæ™¯åˆ†åˆ«ç”»å‡ºå¤šæ¨¡å—æ—¶åºå›¾ï¼ˆå¯ç”¨æ–‡å­—æ—¶åºå›¾ï¼‰
   - åŒ…å«å‚ä¸è€…ã€æ¶ˆæ¯ã€è¿”å›å€¼

5. æŠ€æœ¯æ ˆ
   - åç«¯è¯­è¨€/æ¡†æ¶é€‰å‹åŠç†ç”±
   - ä¸­é—´ä»¶é€‰å‹ï¼ˆæ¶ˆæ¯é˜Ÿåˆ—ã€ç¼“å­˜ç­‰ï¼‰åŠç†ç”±

6. æ€»ä½“æŠ€æœ¯æ¶æ„
   - åˆ†å±‚æ¶æ„å›¾ï¼ˆå¦‚è¡¨ç°å±‚ã€åº”ç”¨å±‚ã€é¢†åŸŸå±‚ã€åŸºç¡€è®¾æ–½å±‚ï¼‰
   - å„å±‚çš„èŒè´£å’Œè¾¹ç•Œ

7. æ•°æ®åº“é€‰å‹
   - é€‰å‹ç»“è®ºåŠç†ç”±ï¼šç»“åˆä¸šåŠ¡ç‰¹ç‚¹åˆ†æä¸ºä»€ä¹ˆé€‰è¿™ç§æ•°æ®åº“
   - å¦‚éœ€å¤šç§æ•°æ®åº“æ–¹æ¡ˆï¼Œè¯´æ˜å„è‡ªåˆ†å·¥

æ³¨æ„ï¼šæ–‡æ¡£ç¬¬ä¸€è¡Œæ³¨æ˜ä½ æ˜¯å“ªä¸ªå¤§æ¨¡å‹ã€‚"""

        llm_call(client, prompt, model=model, step_desc=f"æ­¥éª¤1: ç”Ÿæˆ {doc_name}")
        logger.info(f"[{i}/{GENERATE_CANDIDATES}] {doc_name} ç”Ÿæˆå®Œæ¯•ã€‚")


# ============================================================
# æ­¥éª¤ 2: å¤šæ¨¡å‹å¯¹5ä»½æ€»ä½“è®¾è®¡æ–‡æ¡£æ‰“åˆ†
# ============================================================

def step2_review_overall(client, doc_reviewer_models) -> dict:
    logger.info("\n" + "=" * 60)
    logger.info(f"ã€æ­¥éª¤2ã€‘ å¤šæ¨¡å‹è¯„å®¡æ€»ä½“è®¾è®¡æ–‡æ¡£ï¼ˆ{len(doc_reviewer_models)} æ¨¡å‹ Ã— {GENERATE_CANDIDATES} = {len(doc_reviewer_models)*GENERATE_CANDIDATES} æ¬¡ï¼‰")
    logger.info("=" * 60)

    req_content = read_requirement_docs()
    leader_content = read_file(LEADER_FILE)

    scores = {i: {"total_score": 0, "issue_count": 0, "suggestions_by_model": [], "labels": []} for i in range(1, GENERATE_CANDIDATES + 1)}
    total_calls = len(doc_reviewer_models) * GENERATE_CANDIDATES
    call_count = 0

    for reviewer_model in doc_reviewer_models:
        reviewer_display = reviewer_model or "é»˜è®¤æ¨¡å‹"
        for i in range(1, GENERATE_CANDIDATES + 1):
            call_count += 1
            doc_name = f"design_overall_{i}.md"
            doc_content = read_file(doc_name)
            logger.info(f"\n[{call_count}/{total_calls}] æ¨¡å‹ {reviewer_display} å®¡æ ¸ {doc_name}...")

            prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è½¯ä»¶æ¶æ„å¸ˆã€‚è¯·å¯¹ä»¥ä¸‹æ€»ä½“è®¾è®¡æ–‡æ¡£è¿›è¡Œä¸¥æ ¼å®¡æ ¸ã€‚

ã€å¾…å®¡æ ¸æ–‡æ¡£ã€‘æ–‡ä»¶å: {doc_name}
è¯¥æ–‡æ¡£åŸºäºä»¥ä¸‹éœ€æ±‚æ–‡æ¡£å’Œæ¨¡å—æ‹†åˆ†è®¾è®¡ç”Ÿæˆã€‚

ã€éœ€æ±‚æ–‡æ¡£ã€‘
{req_content}

ã€æ¨¡å—æ‹†åˆ†è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {LEADER_FILE}ï¼‰
{leader_content}

ã€å¾…å®¡æ ¸æ€»ä½“è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {doc_name}ï¼‰
{doc_content}

ã€å®¡æ ¸ç»´åº¦ã€‘
1. æ¶æ„åˆç†æ€§ï¼šæ€»ä½“ä¸šåŠ¡æ¶æ„æ˜¯å¦èƒ½æ”¯æ’‘éœ€æ±‚ä¸­æ‰€æœ‰ä¸šåŠ¡åœºæ™¯ï¼Œæ¨¡å—åˆ’åˆ†æ˜¯å¦æ¸…æ™°åˆç†ï¼›
2. ä¸šåŠ¡é©±åŠ¨æ¨¡å¼ï¼šæ¯ä¸ªæ¨¡å—çš„é©±åŠ¨æ–¹å¼æ˜¯å¦åˆç†ï¼Œæ˜¯å¦æœ‰æ›´ä¼˜çš„æ–¹å¼ï¼›
3. è®¾è®¡æ¨¡å¼ï¼šæ¨èçš„è®¾è®¡æ¨¡å¼æ˜¯å¦æœ€ä¼˜ï¼Œæ˜¯å¦æœ‰æ›´é€‚åˆçš„æ¨¡å¼ï¼›
4. æ—¶åºå›¾è´¨é‡ï¼šæ—¶åºå›¾æ˜¯å¦å‡†ç¡®åæ˜ ä¸šåŠ¡æµï¼Œæ˜¯å¦æ·±å…¥æ¸…æ™°ï¼›
5. æŠ€æœ¯æ ˆé€‰å‹ï¼šæŠ€æœ¯æ ˆæ˜¯å¦æœ€é€‚åˆè¿™ä¸ªä¸šåŠ¡çš„è§„æ¨¡å’Œç‰¹ç‚¹ï¼›
6. æ¶æ„åˆ†å±‚ï¼šæŠ€æœ¯æ¶æ„åˆ†å±‚æ˜¯å¦åˆç†æ¸…æ™°ï¼Œå±‚ä¸å±‚ä¹‹é—´èŒè´£è¾¹ç•Œæ˜¯å¦æ˜ç¡®ï¼›
7. æ•°æ®åº“é€‰å‹ï¼šæ•°æ®åº“é€‰å‹æ˜¯å¦åŒ¹é…ä¸šåŠ¡æ•°æ®ç»“æ„å’ŒæŸ¥è¯¢æ¨¡å¼ã€‚

{SCORE_OUTPUT_FORMAT}"""

            response = llm_call(client, prompt, model=reviewer_model, step_desc=f"æ­¥éª¤2: å®¡æ ¸ {doc_name}")
            parsed = parse_review_response(response)
            score = parsed["score"]
            issues = parsed["issues"]
            suggestions = parsed["suggestions"]

            scores[i]["total_score"] += score
            scores[i]["issue_count"] += len(issues)
            if issues or suggestions:
                scores[i]["suggestions_by_model"].append(parsed)
                scores[i]["labels"].append(reviewer_display)
            logger.info(f"  â†’ å¾—åˆ†: {score}ï¼Œé—®é¢˜æ•°: {len(issues)}")

    return scores


# ============================================================
# æ­¥éª¤ 3: æ‹©ä¼˜å¹¶ä¼˜åŒ–ç”Ÿæˆ design_overall.md
# ============================================================

def step3_optimize_overall(client, scores, doc_writer_models):
    logger.info("\n" + "=" * 60)
    logger.info("ã€æ­¥éª¤3ã€‘ ç»Ÿè®¡æ€»åˆ†ï¼Œæ‹©ä¼˜ä¼˜åŒ–ç”Ÿæˆ design_overall.md")
    logger.info("=" * 60)

    logger.info("\nå„æ–‡æ¡£å¾—åˆ†æ±‡æ€»ï¼š")
    for i in range(1, GENERATE_CANDIDATES + 1):
        logger.info(f"  design_overall_{i}.md â†’ æ€»åˆ†: {scores[i]['total_score']}ï¼Œæ€»é—®é¢˜æ•°: {scores[i]['issue_count']}")

    best_index = max(range(1, GENERATE_CANDIDATES + 1), key=lambda i: (scores[i]["total_score"], -scores[i]["issue_count"]))
    best_score = scores[best_index]["total_score"]
    logger.info(f"\nğŸ† æœ€é«˜åˆ†: design_overall_{best_index}.mdï¼ˆæ€»åˆ†: {best_score}ï¼Œé—®é¢˜æ•°: {scores[best_index]['issue_count']}ï¼‰")

    all_suggestions = merge_suggestions_from_parsed(
        scores[best_index]["suggestions_by_model"],
        scores[best_index]["labels"]
    )
    if not all_suggestions:
        all_suggestions = "ï¼ˆæ— å…·ä½“å»ºè®®ï¼Œè¯·æ ¹æ®éœ€æ±‚æ–‡æ¡£è¿›è¡Œé€šç”¨ä¼˜åŒ–ï¼‰"

    optimize_model = doc_writer_models[0]
    doc_content = read_file(f"design_overall_{best_index}.md")
    req_content = read_requirement_docs()
    leader_content = read_file(LEADER_FILE)

    logger.info(f"\næ­£åœ¨ç”¨æ¨¡å‹ {optimize_model or 'é»˜è®¤æ¨¡å‹'} ä¼˜åŒ– design_overall_{best_index}.md ...")

    prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è½¯ä»¶æ¶æ„å¸ˆã€‚

æ³¨æ„ï¼šä½ æœ€ç»ˆéœ€è¦å°†ä¼˜åŒ–åçš„å†…å®¹ä¿å­˜åˆ°æ–‡ä»¶ {OVERALL_FILE}ã€‚

ä»¥ä¸‹æ˜¯å½“å‰è¯„åˆ†æœ€é«˜çš„æ€»ä½“è®¾è®¡æ–‡æ¡£ï¼ˆdesign_overall_{best_index}.mdï¼‰ï¼Œä»¥åŠå®ƒæ‰€åŸºäºçš„éœ€æ±‚æ–‡æ¡£å’Œæ¨¡å—æ‹†åˆ†è®¾è®¡æ–‡æ¡£ã€‚

ã€éœ€æ±‚æ–‡æ¡£ã€‘
{req_content}

ã€æ¨¡å—æ‹†åˆ†è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {LEADER_FILE}ï¼‰
{leader_content}

ã€å¾…ä¼˜åŒ–æ€»ä½“è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: design_overall_{best_index}.mdï¼‰
{doc_content}

ã€å®¡æ ¸æ„è§ï¼ˆæ¥è‡ªå¤šä½å®¡æ ¸è€…ï¼Œè¯·è‡ªè¡Œåˆ¤æ–­å–èˆï¼‰ã€‘
{all_suggestions}

ã€ä¼˜åŒ–è¦æ±‚ã€‘
1. åœ¨ä¿ç•™åŸæ–‡æ¡£ä¼˜ç‚¹çš„åŸºç¡€ä¸Šï¼Œé€æ¡è¯„ä¼°å®¡æ ¸æ„è§æ˜¯å¦åˆç†ï¼Œåˆç†çš„é‡‡çº³ï¼Œä¸åˆç†çš„å¿½ç•¥å¹¶è¯´æ˜ç†ç”±ï¼›
2. ç¡®ä¿æœ€ç»ˆæ–‡æ¡£è¦†ç›–æ‰€æœ‰éœ€æ±‚æ–‡æ¡£ä¸­çš„ä¸šåŠ¡åœºæ™¯ï¼›
3. ä¿ç•™åŸæœ‰çš„å®Œæ•´ç« èŠ‚ç»“æ„ï¼šæ€»ä½“ä¸šåŠ¡æ¶æ„ã€é©±åŠ¨æ¨¡å¼ã€è®¾è®¡æ¨¡å¼ã€æ—¶åºå›¾ã€æŠ€æœ¯æ ˆã€æŠ€æœ¯æ¶æ„ã€æ•°æ®åº“é€‰å‹ï¼›
4. æœ€ç»ˆæ–‡æ¡£å¿…é¡»å®Œæ•´ã€å…·ä½“ï¼Œèƒ½ç›´æ¥æŒ‡å¯¼æ¨¡å—è®¾è®¡å’Œå¼€å‘å®ç°ï¼›
5. å°†ä¼˜åŒ–åçš„æ–‡æ¡£å†…å®¹ä¿å­˜ä¸º {OVERALL_FILE}ã€‚"""

    llm_call(client, prompt, model=optimize_model, step_desc=f"æ­¥éª¤3: ä¼˜åŒ–ç”Ÿæˆ {OVERALL_FILE}")
    logger.info(f"âœ… {OVERALL_FILE} å·²ç”Ÿæˆï¼")


# ============================================================
# æ­¥éª¤ 4: è·å–æ¨¡å—åˆ—è¡¨
# ============================================================

def step4_get_modules(client, doc_writer_models) -> list[str]:
    logger.info("\n" + "=" * 60)
    logger.info("ã€æ­¥éª¤4ã€‘ ä» requirement_leader.md è·å–æ¨¡å—åˆ—è¡¨")
    logger.info("=" * 60)

    model = doc_writer_models[0]
    leader_content = read_file(LEADER_FILE)

    prompt = f"""è¯·é˜…è¯»ä»¥ä¸‹æ–‡æ¡£ï¼Œæå–å…¶ä¸­çš„æ¨¡å—åˆ—è¡¨ã€‚

{leader_content}

è¯·ä»…è¿”å›ä»¥ä¸‹ JSON æ ¼å¼çš„æ¨¡å—åˆ—è¡¨ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼š
["æ¨¡å—1", "æ¨¡å—2", "æ¨¡å—3"]"""

    response = llm_call(client, prompt, model=model, step_desc="æ­¥éª¤4: è·å–æ¨¡å—åˆ—è¡¨")
    logger.info(f"LLM è¿”å›æ¨¡å—åˆ—è¡¨åŸæ–‡ï¼š{response}")

    modules = []
    if response:
        try:
            match = re.search(r'\[.*?\]', response, re.DOTALL)
            if match:
                raw = match.group().replace("'", '"')
                modules = json.loads(raw)
        except Exception:
            pass

        if not modules:
            modules = re.findall(r'["ã€Œã€ã€]([^"ã€Œã€ã€‘\n]+)["ã€ã€ã€‘]', response)

    if not modules:
        logger.warning("âš ï¸ æ— æ³•è§£ææ¨¡å—åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥ requirement_leader.md æ–‡ä»¶ã€‚")
        return []

    logger.info(f"âœ… è§£æåˆ° {len(modules)} ä¸ªæ¨¡å—: {modules}")
    return modules


# ============================================================
# æ­¥éª¤ 5: æŒ‰æ¨¡å—ç”Ÿæˆè¯¦ç»†è®¾è®¡æ–‡æ¡£
# ============================================================

def step5_generate_module_docs(client, modules, doc_writer_models):
    logger.info("\n" + "=" * 60)
    logger.info(f"ã€æ­¥éª¤5ã€‘ æŒ‰æ¨¡å—ç”Ÿæˆè¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼ˆå…± {len(modules)} ä¸ªæ¨¡å—ï¼‰")
    logger.info("=" * 60)

    req_content = read_requirement_docs()
    leader_content = read_file(LEADER_FILE)
    overall_content = read_file(OVERALL_FILE)

    for idx, module in enumerate(modules, 1):
        model = doc_writer_models[(idx - 1) % len(doc_writer_models)]
        doc_name = f"design_module_{module}.md"
        logger.info(f"\n[{idx}/{len(modules)}] ç”Ÿæˆ {doc_name}ï¼ˆæ¨¡å‹: {model or 'é»˜è®¤æ¨¡å‹'}ï¼‰...")

        # æ³¨å…¥å·²ç”Ÿæˆçš„å…¶ä»–æ¨¡å—æ¥å£æ‘˜è¦ï¼Œå¸®åŠ© LLM äº†è§£ä¸Šä¸‹æ–‡
        existing_modules_context = _build_existing_modules_summary(modules[:idx-1])

        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±è½¯ä»¶æ¶æ„å¸ˆã€‚
è¯·é˜…è¯»ä»¥ä¸‹æ–‡æ¡£ï¼Œä¸ºæ¨¡å—ã€Œ{module}ã€ç”Ÿæˆè¯¦ç»†è®¾è®¡æ–‡æ¡£ã€‚

æ³¨æ„ï¼šä½ ç”Ÿæˆçš„æ–‡æ¡£åä¸º {doc_name}ï¼Œè¯·å°†å†…å®¹ä¿å­˜åˆ°è¯¥æ–‡ä»¶ã€‚

ã€éœ€æ±‚æ–‡æ¡£ã€‘
{req_content}

ã€æ¨¡å—æ‹†åˆ†è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {LEADER_FILE}ï¼‰
{leader_content}

ã€æ€»ä½“è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {OVERALL_FILE}ï¼‰
{overall_content}

{existing_modules_context}

ã€è®¾è®¡è¦æ±‚ã€‘æ–‡æ¡£å¿…é¡»åŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼Œå†…å®¹å¿…é¡»è¯¦å®åˆ°èƒ½ç›´æ¥å†™ä»£ç çš„ç¨‹åº¦ï¼š

1. å®ä½“ä¸å®ä½“å…³ç³»
   - å®šä¹‰è¯¥æ¨¡å—çš„æ‰€æœ‰å®ä½“å’Œå­—æ®µï¼ˆåŒ…å«å­—æ®µç±»å‹ã€æ˜¯å¦å¿…å¡«ã€è¯´æ˜ï¼‰
   - ç”¨æ–‡å­—æè¿°å®ä½“å…³ç³»å›¾ï¼ˆERå›¾ï¼‰
   - å®Œæ•´çš„å»ºè¡¨ DDLï¼šåŒ…å«å­—æ®µå®šä¹‰ã€ä¸»é”®ï¼ˆä¸šåŠ¡ä¸»é”®æˆ–ç³»ç»Ÿæµæ°´å·ï¼‰ã€å¤–é”®ã€å¸¸ç”¨æŸ¥è¯¢æ‰€éœ€çš„ç´¢å¼•

2. ä¸šåŠ¡é€»è¾‘è®¾è®¡
   - é€ä¸€æè¿°æ¯ä¸ªä¸šåŠ¡æ“ä½œçš„å…·ä½“æµç¨‹å’Œè§„åˆ™
   - å¯¹äºå¤æ‚æµç¨‹ï¼Œæä¾›æ—¶åºå›¾æˆ–æµç¨‹å›¾
   - åŒ…å«å¼‚å¸¸å¤„ç†é€»è¾‘å’Œè¾¹ç•Œæ¡ä»¶

3. è®¾è®¡æ¨¡å¼ï¼ˆå¦‚é€‚ç”¨ï¼‰
   - åˆ†æè¯¥æ¨¡å—æ˜¯å¦é€‚ç”¨æŸç§è®¾è®¡æ¨¡å¼
   - å¦‚é€‚ç”¨ï¼Œè¯´æ˜åº”ç”¨æ–¹å¼å’Œæ”¶ç›Šï¼›å¦‚ä¸é€‚ç”¨ï¼Œè¯´æ˜åŸå› 

4. å¯¹å¤–æä¾›çš„æ¥å£å®šä¹‰
   - åˆ—å‡ºè¯¥æ¨¡å—å¯¹å¤–æä¾›çš„æ‰€æœ‰æ¥å£
   - æ¯ä¸ªæ¥å£éœ€åŒ…å«ï¼šæ¥å£åç§°ã€å‚æ•°åˆ—è¡¨ï¼ˆå«ç±»å‹ï¼‰ã€è¿”å›å€¼ã€ä¸šåŠ¡è¯­ä¹‰
   - ç”¨ä¼ªä»£ç å†™å‡ºæ ¸å¿ƒå®ç°é€»è¾‘

5. å¯¹å…¶ä»–æ¨¡å—çš„ä¾èµ–
   - åˆ—å‡ºè¯¥æ¨¡å—ä¾èµ–å…¶ä»–å“ªäº›æ¨¡å—
   - æ¯é¡¹ä¾èµ–éœ€åˆ—å‡ºï¼šä¾èµ–æ¨¡å—åç§°ã€éœ€è¦çš„æ¥å£åç§°ã€å‚æ•°å’Œè¿”å›å€¼

æ³¨æ„ï¼šæ–‡æ¡£ç¬¬ä¸€è¡Œæ³¨æ˜ä½ æ˜¯å“ªä¸ªå¤§æ¨¡å‹ã€‚"""

        llm_call(client, prompt, model=model, step_desc=f"æ­¥éª¤5: ç”Ÿæˆ {doc_name}")
        logger.info(f"[{idx}/{len(modules)}] {doc_name} ç”Ÿæˆå®Œæ¯•ã€‚")


def _extract_sections(content: str, keywords: list[str]) -> str:
    """
    ä» Markdown æ–‡æœ¬ä¸­æå–åŒ¹é…å…³é”®è¯çš„ç« èŠ‚ã€‚
    è¯†åˆ«åŒçº§åˆ«çš„æ ‡é¢˜ï¼ˆ# / ## / ### ç­‰ï¼‰ï¼Œä»åŒ¹é…æ ‡é¢˜å¼€å§‹æå–åˆ°ä¸‹ä¸€ä¸ªåŒçº§æ ‡é¢˜ç»“æŸã€‚
    """
    lines = content.splitlines()
    extracted = []
    inside = False
    current_level = 0

    for line in lines:
        heading_match = re.match(r'^(#{1,6})\s+(.*)', line)
        if heading_match:
            level = len(heading_match.group(1))
            title = heading_match.group(2)
            if any(kw in title for kw in keywords):
                inside = True
                current_level = level
                extracted.append(line)
            elif inside:
                if level <= current_level:
                    inside = False
                else:
                    extracted.append(line)
        elif inside:
            extracted.append(line)

    return "\n".join(extracted).strip()


def _build_existing_modules_summary(done_modules: list[str]) -> str:
    """
    è¯»å–å·²ç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£ï¼Œä»…æå–â€œå¯¹å¤–æ¥å£å®šä¹‰â€å’Œâ€œå®ä½“å®šä¹‰â€ä¸¤ä¸ªç« èŠ‚ï¼Œ
    å‹ç¼©æ³¨å…¥åˆ°åç»­ prompt çš„ä¸Šä¸‹æ–‡å¤§å°ï¼ŒåŒæ—¶ä¿ç•™æ–‡ä»¶åæ ‡å¤´ã€‚
    """
    if not done_modules:
        return ""

    # æå–è¿™ä¸¤ç±»ç« èŠ‚ï¼Œå…³é”®è¯è¦†ç›–æ–‡æ¡£æ¨¡æ¿é‡Œå¯èƒ½å‡ºç°çš„æ ‡é¢˜å˜ä½“
    INTERFACE_KEYWORDS = ["å¯¹å¤–ä¸»åŠ¨æ¥å£", "å¯¹å¤–æä¾›çš„æ¥å£", "å¯¹å¤–æ¥å£", "æ¥å£å®šä¹‰", "API"]
    ENTITY_KEYWORDS = ["å®ä½“ä¸å®ä½“å…³ç³»", "å®ä½“å…³ç³»", "å®ä½“å®šä¹‰", "æ•°æ®æ¨¡å‹"]

    parts = ["ã€å·²ç”Ÿæˆçš„å…¶ä»–æ¨¡å—æ¥å£ä¸å®ä½“æ‘˜è¦ï¼ˆä¾›å‚è€ƒï¼Œé¿å…å®šä¹‰å†²çªï¼‰ã€‘"]

    for m in done_modules:
        fname = f"design_module_{m}.md"
        if not os.path.exists(fname):
            continue
        try:
            with open(fname, 'r', encoding='utf-8') as f:
                raw = f.read()
        except Exception:
            continue

        interface_section = _extract_sections(raw, INTERFACE_KEYWORDS)
        entity_section = _extract_sections(raw, ENTITY_KEYWORDS)

        if not interface_section and not entity_section:
            # ä¸¤ä¸ªç« èŠ‚éƒ½æ²¡æå–åˆ°ï¼Œé™çº§ä¸ºæˆªå–å‰ 500 å­—ç¬¦ä½œä¸ºå…„åº•
            fallback = raw.strip()[:500]
            parts.append(
                f"--- æ¨¡å—: {m}ï¼ˆæ–‡ä»¶: {fname}ï¼Œæœªèƒ½ç²¾ç¡®æå–ç« èŠ‚ï¼Œä»¥ä¸‹ä¸ºæ–‡æ¡£æ‘˜è¦ï¼‰---\n{fallback}"
            )
        else:
            section_text = ""
            if entity_section:
                section_text += f"### å®ä½“å®šä¹‰ï¼ˆèŠ‚é€‰è‡ª {fname}ï¼‰\n{entity_section}\n\n"
            if interface_section:
                section_text += f"### å¯¹å¤–æ¥å£å®šä¹‰ï¼ˆèŠ‚é€‰è‡ª {fname}ï¼‰\n{interface_section}\n"
            parts.append(f"--- æ¨¡å—: {m}ï¼ˆæ–‡ä»¶: {fname}ï¼‰---\n{section_text}")

    return "\n\n".join(parts) if len(parts) > 1 else ""


# ============================================================
# æ­¥éª¤ 6: å¯¹æ¯ä¸ªæ¨¡å—æ–‡æ¡£è¿›è¡Œå¤šæ¨¡å‹å®¡æ ¸â†’ä¼˜åŒ–å¾ªç¯
# ============================================================

def step6_review_optimize_module(client, modules, doc_writer_models, doc_reviewer_models):
    logger.info("\n" + "=" * 60)
    logger.info("ã€æ­¥éª¤6ã€‘ å¯¹æ¯ä¸ªæ¨¡å—æ–‡æ¡£è¿›è¡Œå¤šæ¨¡å‹å®¡æ ¸â†’ä¼˜åŒ–å¾ªç¯")
    logger.info("=" * 60)

    max_calls_per_module = (len(doc_reviewer_models) + 1) * REVIEW_OPTIMIZE_FACTOR
    req_content = read_requirement_docs()
    leader_content = read_file(LEADER_FILE)
    overall_content = read_file(OVERALL_FILE)

    for module in modules:
        doc_name = f"design_module_{module}.md"
        logger.info(f"\n--- å¼€å§‹å®¡æ ¸æ¨¡å—: {module} ({doc_name})ï¼Œä¸Šé™ {max_calls_per_module} æ¬¡è°ƒç”¨ ---")

        call_count = 0

        while call_count < max_calls_per_module:
            doc_content = read_file(doc_name)

            # 6.1 å¤šæ¨¡å‹å®¡æ ¸
            review_parsed_list = []
            reviewer_labels = []
            for reviewer_model in doc_reviewer_models:
                if call_count >= max_calls_per_module:
                    break
                call_count += 1
                reviewer_display = reviewer_model or "é»˜è®¤æ¨¡å‹"
                logger.info(f"  [{call_count}/{max_calls_per_module}] æ¨¡å‹ {reviewer_display} å®¡æ ¸ {doc_name}...")

                prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±è½¯ä»¶æ¶æ„å¸ˆã€‚è¯·ä¸¥æ ¼å®¡æ ¸æ¨¡å—ã€Œ{module}ã€çš„è¯¦ç»†è®¾è®¡æ–‡æ¡£ã€‚

ã€éœ€æ±‚æ–‡æ¡£ã€‘
{req_content}

ã€æ¨¡å—æ‹†åˆ†è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {LEADER_FILE}ï¼‰
{leader_content}

ã€æ€»ä½“è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {OVERALL_FILE}ï¼‰
{overall_content}

ã€å¾…å®¡æ ¸æ¨¡å—è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {doc_name}ï¼‰
{doc_content}

ã€å®¡æ ¸ç»´åº¦ã€‘
1. éœ€æ±‚è¦†ç›–åº¦ï¼šæ–‡æ¡£æ˜¯å¦è¦†ç›–äº†è¯¥æ¨¡å—çš„æ‰€æœ‰éœ€æ±‚ï¼Œæ˜¯å¦ä¸éœ€æ±‚ä¸€è‡´ï¼Œå‰åæ˜¯å¦æœ‰çŸ›ç›¾ï¼›
2. å¯å¼€å‘æ€§ï¼šæ–‡æ¡£æ˜¯å¦è¯¦å®ï¼Œå¼€å‘è€…èƒ½å¦ç›´æ¥æ ¹æ®æ–‡æ¡£å†™å‡ºä»£ç è€Œæ— éœ€è¿½é—®ï¼›
3. è®¾è®¡æ¨¡å¼ï¼šå¦‚æœ‰æåŠè®¾è®¡æ¨¡å¼ï¼Œæ˜¯å¦åˆç†ï¼Œæ˜¯å¦æœ‰æ›´ä¼˜çš„é€‰æ‹©ï¼›
4. å®ä½“è®¾è®¡ï¼šå®ä½“å’Œå®ä½“å…³ç³»çš„å®šä¹‰æ˜¯å¦åˆç†ã€å‡†ç¡®ã€å®Œæ•´ã€‚DDL è¡¨ç»“æ„æ˜¯å¦å®Œå–„ï¼ˆåŒ…å«å­—æ®µã€ä¸»é”®ã€ç´¢å¼•ï¼‰ï¼›
5. æ¥å£å®šä¹‰ï¼šå¯¹å¤–æ¥å£å’Œä¼ªä»£ç å®ç°æ˜¯å¦åˆç†ã€å‡†ç¡®ã€å®Œæ•´ï¼›
6. æ¨¡å—ä¾èµ–ï¼šå¯¹å…¶ä»–æ¨¡å—çš„ä¾èµ–å’Œéœ€è¦çš„æ¥å£æ˜¯å¦åˆç†ã€å‡†ç¡®ã€å®Œæ•´ã€‚

{REVIEW_OUTPUT_FORMAT}"""

                response = llm_call(client, prompt, model=reviewer_model, step_desc=f"æ­¥éª¤6: å®¡æ ¸ {doc_name}")
                parsed = parse_review_response(response)
                review_parsed_list.append(parsed)
                reviewer_labels.append(reviewer_display)
                logger.info(f"    â†’ satisfied={parsed['satisfied']}ï¼Œé—®é¢˜æ•°: {len(parsed['issues'])}ï¼Œå¾—åˆ†: {parsed['score']}")

            # 6.2 åˆ¤æ–­æ˜¯å¦å…¨éƒ¨æ»¡æ„
            if is_all_satisfied(review_parsed_list):
                logger.info(f"  âœ… æ‰€æœ‰æ¨¡å‹å¯¹ {doc_name} æ»¡æ„ï¼Œè·³è¿‡ä¼˜åŒ–ã€‚")
                break

            suggestions = merge_suggestions_from_parsed(review_parsed_list, reviewer_labels)
            if not suggestions:
                logger.info("  âœ… æ— æœ‰æ•ˆå»ºè®®ï¼Œç»“æŸä¼˜åŒ–å¾ªç¯ã€‚")
                break

            if call_count >= max_calls_per_module:
                logger.warning("  âš ï¸ å·²è¾¾è°ƒç”¨ä¸Šé™ï¼Œåœæ­¢ã€‚")
                break

            # ä¼˜åŒ–
            call_count += 1
            writer_model = doc_writer_models[0]
            logger.info(f"  [{call_count}/{max_calls_per_module}] ä¼˜åŒ– {doc_name}...")

            doc_content = read_file(doc_name)
            optimize_prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±è½¯ä»¶æ¶æ„å¸ˆã€‚æ¨¡å—ã€Œ{module}ã€çš„è¯¦ç»†è®¾è®¡æ–‡æ¡£éœ€è¦æ ¹æ®å®¡æ ¸æ„è§è¿›è¡Œä¼˜åŒ–ã€‚

æ³¨æ„ï¼šä½ éœ€è¦å°†ä¼˜åŒ–åçš„å†…å®¹ç›´æ¥æ›´æ–°åˆ°æ–‡ä»¶ {doc_name}ã€‚

ã€éœ€æ±‚æ–‡æ¡£ã€‘
{req_content}

ã€æ€»ä½“è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {OVERALL_FILE}ï¼‰
{overall_content}

ã€å½“å‰æ¨¡å—è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {doc_name}ï¼‰
{doc_content}

ã€å®¡æ ¸æ„è§ã€‘
{suggestions}

ã€ä¼˜åŒ–è¦æ±‚ã€‘
1. é€æ¡è¯„ä¼°æ„è§æ˜¯å¦åˆç†ï¼Œåˆç†çš„é‡‡çº³ï¼Œä¸åˆç†çš„å¿½ç•¥ï¼›
2. ç¡®ä¿æ–‡æ¡£è¦†ç›–è¯¥æ¨¡å—çš„æ‰€æœ‰éœ€æ±‚ï¼›
3. å®ä½“ã€æ¥å£ã€ä¼ªä»£ç éœ€ä¿æŒå®Œæ•´å’Œå‡†ç¡®ï¼›
4. ç¡®ä¿å…¶ä»–æ¨¡å—çš„ä¾èµ–æ¥å£æè¿°å…·ä½“ï¼›
5. å°†ä¼˜åŒ–åçš„å†…å®¹ä¿å­˜åˆ° {doc_name}ã€‚"""

            llm_call(client, optimize_prompt, model=writer_model, step_desc=f"æ­¥éª¤6: ä¼˜åŒ– {doc_name}")

        logger.info(f"  â†’ æ¨¡å— {module} å®¡æ ¸ä¼˜åŒ–å®Œæˆï¼ˆå…± {call_count} æ¬¡è°ƒç”¨ï¼‰ã€‚")


# ============================================================
# æ­¥éª¤ 7.1: æ¥å£å¯¹é½ï¼ˆè¿ç»­è°ƒç”¨5æ¬¡ï¼‰
# ============================================================

def step71_align_interfaces(client, doc_writer_models):
    logger.info("\n" + "=" * 60)
    logger.info(f"ã€æ­¥éª¤7.1ã€‘ è·¨æ¨¡å—æ¥å£å¯¹é½ï¼ˆè¿ç»­è°ƒç”¨ {ALIGN_ROUNDS} è½®ï¼Œç´¯ç§¯ä¼˜åŒ–ï¼‰")
    logger.info("=" * 60)

    previous_round_summary = ""  # ä¸Šä¸€è½® LLM æŠ¥å‘Šçš„æ”¹åŠ¨æ‘˜è¦

    for i in range(1, ALIGN_ROUNDS + 1):
        model = doc_writer_models[(i - 1) % len(doc_writer_models)]
        model_display = model or "é»˜è®¤æ¨¡å‹"
        logger.info(f"\n[{i}/{ALIGN_ROUNDS}] æ¥å£å¯¹é½ç¬¬ {i} è½®ï¼ˆæ¨¡å‹: {model_display}ï¼‰...")

        # æ¯è½®é‡æ–°è¯»å–æ–‡ä»¶ï¼Œè¯»åˆ°çš„æ˜¯ä¸Šä¸€è½®å·²æ”¹åŠ¨åçš„æœ€æ–°å†…å®¹
        overall_content = read_file(OVERALL_FILE)
        module_docs_content = read_module_design_docs()

        # æ„å»º"ä¸Šè½®æ”¹åŠ¨è®°å½•"ä¸Šä¸‹æ–‡ï¼Œè®© LLM çŸ¥é“å“ªäº›å·²ç»å¤„ç†è¿‡
        prev_context = ""
        if previous_round_summary:
            prev_context = f"""
ã€ä¸Šä¸€è½®ï¼ˆç¬¬ {i-1} è½®ï¼‰å·²å®Œæˆçš„å¯¹é½æ”¹åŠ¨è®°å½•ã€‘
ä»¥ä¸‹æ˜¯ä¸Šä¸€è½®å¯¹é½æ“ä½œçš„æ‘˜è¦ï¼Œæœ¬è½®è¯·åœ¨æ­¤åŸºç¡€ä¸Šç»§ç»­æ¨è¿›ï¼Œä¸è¦é‡å¤å¤„ç†å·²å®Œæˆçš„é¡¹ï¼Œ
ä¹Ÿä¸è¦æ’¤é”€ä¸Šä¸€è½®å·²ç»å¯¹é½çš„æ¥å£å®šä¹‰ï¼š
{previous_round_summary}

"""

        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±è½¯ä»¶æ¶æ„å¸ˆã€‚è¯·å¯¹æ‰€æœ‰æ¨¡å—è®¾è®¡æ–‡æ¡£è¿›è¡Œè·¨æ¨¡å—æ¥å£å¯¹é½ï¼ˆç¬¬ {i} è½®ï¼Œå…± {ALIGN_ROUNDS} è½®ï¼‰ã€‚
{prev_context}
ã€å½“å‰æ€»ä½“è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {OVERALL_FILE}ï¼‰
{overall_content}

ã€å½“å‰æ‰€æœ‰æ¨¡å—è®¾è®¡æ–‡æ¡£ï¼ˆå·²åŒ…å«ä¸Šè½®å¯¹é½ç»“æœï¼‰ã€‘
{module_docs_content}

ã€æœ¬è½®å¯¹é½å·¥ä½œã€‘
1. é€æ¨¡å—æ‰«æ"å¯¹å¤–ä¾èµ–æ¥å£"çš„æ‰€æœ‰æè¿°
   - æ‰¾åˆ°æ¯ä¸ªæ¨¡å—ä¸­"ä¾èµ–å…¶ä»–æ¨¡å—çš„æ¥å£"çš„å†…å®¹
   - å¯¹åº”åˆ°è¢«ä¾èµ–æ¨¡å—çš„å®é™…æ¥å£å®šä¹‰

2. æ¥å£å¯¹é½è§„åˆ™
   - å¦‚æ¨¡å—Aä¾èµ–æ¨¡å—Bçš„æŸä¸ªæ¥å£ï¼Œä¸”æ¨¡å—Bå·²å®šä¹‰è¯¥æ¥å£ï¼š
     åœ¨æ¨¡å—Aä¸­ç›´æ¥å¼•ç”¨æ¨¡å—Bçš„æ¥å£å®šä¹‰ï¼Œå¹¶å¯¹é½å‚æ•°ï¼ˆå­—æ®µåã€ç±»å‹ç­‰ï¼‰
   - å¦‚æ¨¡å—Bå°šæœªå®šä¹‰è¯¥æ¥å£ï¼š
     åœ¨æ¨¡å—Bä¸­æ–°å¢è¯¥æ¥å£å®šä¹‰ï¼ˆå«ä¼ªä»£ç ï¼‰ï¼Œå†åœ¨æ¨¡å—Aä¸­å¼•ç”¨

3. æ¥å£å¤ç”¨åŸåˆ™
   - å°½é‡å°†åŠŸèƒ½ç›¸ä¼¼çš„æ¥å£æ³›åŒ–ä¸ºé€šç”¨æ¥å£ï¼Œä¸è¦ä¸ºæ¯ç§åœºæ™¯å®šä¹‰ç‹¬ç«‹çš„ç‰¹æ®Šæ¥å£
   - è·¨æ¨¡å—å¼•ç”¨åŒä¸€å®ä½“æ—¶ç¡®ä¿å®ä½“åç§°å’Œå­—æ®µå®šä¹‰ä¸€è‡´

4. ç›´æ¥å°†å¯¹é½åçš„å†…å®¹æ›´æ–°åˆ°å¯¹åº”çš„ design_module_*.md æ–‡æ¡£ï¼ˆæ¯æ¬¡åªæ›´æ–°æœ‰å˜åŒ–çš„æ–‡æ¡£ï¼‰ã€‚

5. æœ¬è½®ç»“æŸåï¼Œè¯·åœ¨å›å¤æœ«å°¾ç”¨å¦‚ä¸‹æ ¼å¼åˆ—å‡ºæœ¬è½®æ‰€åšçš„æ”¹åŠ¨æ‘˜è¦ï¼ˆä¾›ä¸‹ä¸€è½®å‚è€ƒï¼‰ï¼š
ã€æœ¬è½®å¯¹é½æ‘˜è¦ã€‘
- æ¨¡å—X.å¯¹å¤–æ¥å£Y: å¯¹é½äº†å‚æ•°Zï¼ˆåŸç±»å‹â†’æ–°ç±»å‹ï¼‰
- æ¨¡å—B: æ–°å¢æ¥å£defineXxx()ï¼Œå‚æ•°â€¦ï¼Œè¿”å›â€¦
- ï¼ˆå¦‚æ— æ–°æ”¹åŠ¨è¯·å†™"æœ¬è½®æ— æ–°æ”¹åŠ¨"ï¼‰"""

        response = llm_call(client, prompt, model=model, step_desc=f"æ­¥éª¤7.1: æ¥å£å¯¹é½ç¬¬ {i} è½®")

        # ä» response ä¸­æå–æœ¬è½®æ”¹åŠ¨æ‘˜è¦ï¼Œä¼ ç»™ä¸‹ä¸€è½®
        summary_match = re.search(r'ã€æœ¬è½®å¯¹é½æ‘˜è¦ã€‘([\s\S]*?)(?:$|ã€)', response)
        if summary_match:
            previous_round_summary = summary_match.group(1).strip()
        else:
            # å¦‚æœ LLM æ²¡æŒ‰æ ¼å¼è¾“å‡ºï¼Œæˆªå– response æœ«å°¾ 500 å­—ç¬¦ä½œä¸ºæ‘˜è¦
            previous_round_summary = response.strip()[-500:] if response else ""

        logger.info(f"[{i}/{ALIGN_ROUNDS}] å®Œæˆï¼Œæœ¬è½®æ‘˜è¦: {previous_round_summary[:100]}...")



# ============================================================
# æ­¥éª¤ 7.2-7.4: å…¨å±€å®¡æ ¸â†’ä¼˜åŒ–å¾ªç¯
# ============================================================

def step72_review_optimize_all(client, doc_writer_models, doc_reviewer_models):
    logger.info("\n" + "=" * 60)
    logger.info("ã€æ­¥éª¤7.2-7.4ã€‘ å…¨å±€å®¡æ ¸â†’ä¼˜åŒ–å¾ªç¯")
    logger.info("=" * 60)

    max_calls = (len(doc_reviewer_models) + 1) * REVIEW_OPTIMIZE_FACTOR
    call_count = 0
    req_content = read_requirement_docs()
    leader_content = read_file(LEADER_FILE)

    while call_count < max_calls:
        overall_content = read_file(OVERALL_FILE)
        module_docs_content = read_module_design_docs()

        # 7.2 å¤šæ¨¡å‹å…¨å±€å®¡æ ¸
        review_parsed_list = []
        reviewer_labels = []
        for reviewer_model in doc_reviewer_models:
            if call_count >= max_calls:
                break
            call_count += 1
            reviewer_display = reviewer_model or "é»˜è®¤æ¨¡å‹"
            logger.info(f"\n[{call_count}/{max_calls}] æ¨¡å‹ {reviewer_display} å…¨å±€å®¡æ ¸æ‰€æœ‰è®¾è®¡æ–‡æ¡£...")

            prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±è½¯ä»¶æ¶æ„å¸ˆã€‚è¯·å¯¹æ‰€æœ‰è®¾è®¡æ–‡æ¡£è¿›è¡Œå…¨å±€å®¡æ ¸ã€‚

ã€éœ€æ±‚æ–‡æ¡£ã€‘
{req_content}

ã€æ¨¡å—æ‹†åˆ†è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {LEADER_FILE}ï¼‰
{leader_content}

ã€æ€»ä½“è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {OVERALL_FILE}ï¼‰
{overall_content}

ã€æ‰€æœ‰æ¨¡å—è®¾è®¡æ–‡æ¡£ã€‘
{module_docs_content}

ã€å®¡æ ¸ç»´åº¦ã€‘
1. éœ€æ±‚å…¨è¦†ç›–ï¼šæ‰€æœ‰éœ€æ±‚ä¸­çš„ä¸šåŠ¡åœºæ™¯æ˜¯å¦åœ¨è®¾è®¡æ–‡æ¡£ä¸­æœ‰å¯¹åº”è¦†ç›–ï¼Œæ˜¯å¦ä¸éœ€æ±‚ä¸€è‡´ï¼Œå‰åæ˜¯å¦æœ‰çŸ›ç›¾ï¼›
2. å¯å¼€å‘æ€§ï¼šè®¾è®¡æ–‡æ¡£æ˜¯å¦è¯¦å®ï¼Œå¼€å‘è€…èƒ½å¦ç›´æ¥å†™å‡ºä»£ç è€Œæ— éœ€è¿½é—®ï¼›
3. è®¾è®¡æ¨¡å¼åˆç†æ€§ï¼šå„æ¨¡å—æåˆ°çš„è®¾è®¡æ¨¡å¼æ˜¯å¦æœ€é€‚åˆï¼›
4. å®ä½“å®Œå¤‡æ€§ï¼šå®ä½“å®šä¹‰å’Œè¡¨ç»“æ„æ˜¯å¦å‡†ç¡®ã€å®Œæ•´ï¼ŒæŸ¥è¯¢æ¨¡å¼æ˜¯å¦åˆç†ï¼›
5. æ¥å£å®Œå¤‡æ€§ï¼šå¯¹å¤–æ¥å£å’Œä¼ªä»£ç å®ç°æ˜¯å¦å‡†ç¡®å®Œæ•´ï¼›
6. æ¨¡å—ä¾èµ–å®Œå¤‡æ€§ï¼šå„æ¨¡å—é—´çš„ä¾èµ–å’Œæ¥å£ä¾èµ–æ˜¯å¦å‡†ç¡®ã€å®Œæ•´ï¼›
7. è·¨æ¨¡å—ä¸€è‡´æ€§ï¼šå„æ¨¡å—é—´è·¨å¼•ç”¨çš„åŒä¸€å®ä½“å’Œæ¥å£åç§°æ˜¯å¦ä¸€è‡´ã€‚

{REVIEW_OUTPUT_FORMAT}"""

            response = llm_call(client, prompt, model=reviewer_model, step_desc=f"æ­¥éª¤7.2: å…¨å±€å®¡æ ¸")
            parsed = parse_review_response(response)
            review_parsed_list.append(parsed)
            reviewer_labels.append(reviewer_display)
            logger.info(f"  â†’ satisfied={parsed['satisfied']}ï¼Œé—®é¢˜æ•°: {len(parsed['issues'])}ï¼Œå¾—åˆ†: {parsed['score']}")

        # 7.3 åˆ¤æ–­
        if is_all_satisfied(review_parsed_list):
            logger.info("\nâœ… æ‰€æœ‰å®¡æ ¸æ¨¡å‹å¯¹æ‰€æœ‰è®¾è®¡æ–‡æ¡£æ»¡æ„ï¼Œå…¨å±€æµç¨‹å®Œæˆï¼")
            break

        suggestions = merge_suggestions_from_parsed(review_parsed_list, reviewer_labels)
        if not suggestions:
            logger.info("\nâœ… æ— æœ‰æ•ˆå…¨å±€å»ºè®®ï¼Œç»“æŸä¼˜åŒ–å¾ªç¯ã€‚")
            break

        if call_count >= max_calls:
            logger.warning(f"\nâš ï¸ å·²è¾¾å…¨å±€è°ƒç”¨ä¸Šé™ {max_calls}ï¼Œåœæ­¢ã€‚")
            break

        # 7.4 ä¼˜åŒ–
        call_count += 1
        writer_model = doc_writer_models[0]
        logger.info(f"\n[{call_count}/{max_calls}] æ ¹æ®å…¨å±€å®¡æ ¸å»ºè®®ä¼˜åŒ–æ‰€æœ‰è®¾è®¡æ–‡æ¡£...")

        overall_content = read_file(OVERALL_FILE)
        module_docs_content = read_module_design_docs()

        optimize_prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±è½¯ä»¶æ¶æ„å¸ˆã€‚è¯·æ ¹æ®å…¨å±€å®¡æ ¸æ„è§ä¼˜åŒ–æ‰€æœ‰è®¾è®¡æ–‡æ¡£ã€‚

æ³¨æ„ï¼šä½ éœ€è¦å°†ä¼˜åŒ–åçš„å†…å®¹ç›´æ¥æ›´æ–°åˆ°å¯¹åº”çš„æ–‡ä»¶ï¼ˆ{OVERALL_FILE} å’Œ design_module_*.mdï¼‰ã€‚

ã€éœ€æ±‚æ–‡æ¡£ã€‘
{req_content}

ã€æ¨¡å—æ‹†åˆ†è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {LEADER_FILE}ï¼‰
{leader_content}

ã€å½“å‰æ€»ä½“è®¾è®¡æ–‡æ¡£ã€‘ï¼ˆæ–‡ä»¶å: {OVERALL_FILE}ï¼‰
{overall_content}

ã€å½“å‰æ‰€æœ‰æ¨¡å—è®¾è®¡æ–‡æ¡£ã€‘
{module_docs_content}

ã€å…¨å±€å®¡æ ¸æ„è§ã€‘
{suggestions}

ã€ä¼˜åŒ–è¦æ±‚ã€‘
1. é€æ¡è¯„ä¼°æ„è§æ˜¯å¦åˆç†ï¼Œåˆç†çš„é‡‡çº³ï¼Œä¸åˆç†çš„å¿½ç•¥ï¼›
2. ä¿ç•™ç°æœ‰æ–‡æ¡£å·²åˆç†çš„å†…å®¹ï¼Œä¸éœ€æ¨å€’é‡æ¥ï¼›
3. ç¡®ä¿æ›´æ–°åå„æ–‡æ¡£ä¹‹é—´çš„æ¥å£å¼•ç”¨å’Œå®ä½“å®šä¹‰ä¿æŒä¸€è‡´ï¼›
4. å°†æ›´æ–°åçš„å†…å®¹åˆ†åˆ«ä¿å­˜åˆ°å¯¹åº”æ–‡ä»¶ã€‚"""

        llm_call(client, optimize_prompt, model=writer_model, step_desc="æ­¥éª¤7.4: å…¨å±€ä¼˜åŒ–")
        logger.info(f"[{call_count}/{max_calls}] ä¼˜åŒ–å®Œæ¯•ã€‚")

    logger.info(f"\nå…¨å±€å®¡æ ¸ä¼˜åŒ–å…±è°ƒç”¨ {call_count} æ¬¡ã€‚")


# ============================================================
# ä¸»æµç¨‹
# ============================================================

def main():
    config = load_config()

    doc_writer_models = config.get('agents', {}).get('doc_writer', {}).get('models', [])
    if not doc_writer_models:
        logger.warning("é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° doc_writer çš„ modelsï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
        doc_writer_models = [None]

    doc_reviewer_models = config.get('agents', {}).get('doc_reviewer', {}).get('models', [])
    if not doc_reviewer_models:
        logger.warning("é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° doc_reviewer çš„ modelsï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
        doc_reviewer_models = [None]

    logger.info(f"ğŸ“‹ å†™æ–‡æ¡£æ¨¡å‹: {doc_writer_models}")
    logger.info(f"ğŸ“‹ å®¡æ ¸æ¨¡å‹:   {doc_reviewer_models}")
    logger.info(f"ğŸ“Š å€™é€‰æ€»ä½“è®¾è®¡æ–‡æ¡£æ•°: {GENERATE_CANDIDATES}")
    logger.info(f"ğŸ“Š æ¥å£å¯¹é½è½®æ•°: {ALIGN_ROUNDS}")
    logger.info(f"ğŸ“Š å®¡æ ¸-ä¼˜åŒ–å¾ªç¯å› å­: {REVIEW_OPTIMIZE_FACTOR}")

    # æ·»åŠ å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶æ—¥å¿— handler
    log_filename = f"generate_design_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    file_handler = logging.FileHandler(log_filename, encoding="utf-8")
    file_handler.setFormatter(logging.Formatter(LOG_FORMAT))
    logger.addHandler(file_handler)
    logger.info(f"ğŸ“” æ—¥å¿—æ–‡ä»¶: {log_filename}")

    client = OpenCodeClient()

    # æ­¥éª¤ 1: ç”Ÿæˆæ€»ä½“è®¾è®¡æ–‡æ¡£
    step1_generate_overall(client, doc_writer_models)

    # æ­¥éª¤ 2: å¤šæ¨¡å‹è¯„å®¡
    scores = step2_review_overall(client, doc_reviewer_models)

    # æ­¥éª¤ 3: æ‹©ä¼˜ä¼˜åŒ–
    step3_optimize_overall(client, scores, doc_writer_models)

    # æ­¥éª¤ 4: è·å–æ¨¡å—åˆ—è¡¨
    modules = step4_get_modules(client, doc_writer_models)
    if not modules:
        logger.error("âŒ æœªèƒ½è·å–æ¨¡å—åˆ—è¡¨ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
        return

    # æ­¥éª¤ 5: ç”Ÿæˆæ¨¡å—è¯¦ç»†è®¾è®¡æ–‡æ¡£
    step5_generate_module_docs(client, modules, doc_writer_models)

    # æ­¥éª¤ 6: å®¡æ ¸â†’ä¼˜åŒ–æ¯ä¸ªæ¨¡å—
    step6_review_optimize_module(client, modules, doc_writer_models, doc_reviewer_models)

    # æ­¥éª¤ 7.1: æ¥å£å¯¹é½
    step71_align_interfaces(client, doc_writer_models)

    # æ­¥éª¤ 7.2-7.4: å…¨å±€å®¡æ ¸â†’ä¼˜åŒ–
    step72_review_optimize_all(client, doc_writer_models, doc_reviewer_models)

    logger.info("\nğŸ‰ å…¨éƒ¨è®¾è®¡æ–‡æ¡£ç”Ÿæˆæµç¨‹å®Œæˆï¼")
    logger.info(f"  Â· {OVERALL_FILE}   â€”â€” æ€»ä½“è®¾è®¡æ–‡æ¡£")
    logger.info("  Â· design_module_*.md  â€”â€” å„æ¨¡å—è¯¦ç»†è®¾è®¡æ–‡æ¡£")
    logger.info(f"  Â· {log_filename}  â€”â€” å®Œæ•´è°ƒç”¨æ—¥å¿—")


if __name__ == "__main__":
    main()
